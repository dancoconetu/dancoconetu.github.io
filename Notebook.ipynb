{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"nypd.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping empty columns values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.dropna(subset=['LATITUDE'], inplace=True)\n",
    "df.dropna(subset=['LONGITUDE'], inplace=True)\n",
    "df.dropna(subset=['CONTRIBUTING FACTOR VEHICLE 1'], inplace=True)\n",
    "df = df.drop(df[df['CONTRIBUTING FACTOR VEHICLE 1'] =='Unspecified'].index)\n",
    "inattetion =  df.loc[df['CONTRIBUTING FACTOR VEHICLE 1'] == \"Driver Inattention/Distraction\"]\n",
    "failure = df.loc[df['CONTRIBUTING FACTOR VEHICLE 1'] == \"Failure to Yield Right-of-Way\"]\n",
    "otherVehicle = df.loc[df['CONTRIBUTING FACTOR VEHICLE 1'] == \"Other Vehicular\"]\n",
    "fatigued =  df.loc[df['CONTRIBUTING FACTOR VEHICLE 1'] == \"Fatigued/Drowsy\"]\n",
    "inattention25k = inattetion.iloc[-10000:]\n",
    "otherVehicle25k = otherVehicle.iloc[-10000:]\n",
    "failure25k = failure.iloc[-10000:]\n",
    "fatigued25k = fatigued.iloc[-10000:]\n",
    "minLat, minLon = 40.499186, -74.251609\n",
    "maxLat, maxLon = 40.977385, -73.648929\n",
    "minLat =  min(df[df['LATITUDE']>39]['LATITUDE'])\n",
    "maxLat = max(df[df['LATITUDE']>39]['LATITUDE'])\n",
    "minLon =  min(df[df['LONGITUDE']>-175]['LONGITUDE'])\n",
    "maxLon =  max(df[df['LONGITUDE']<-72]['LONGITUDE'])\n",
    "latIncrease = (maxLat- minLat)/50.0\n",
    "lonIncrease = (maxLon - minLon)/50.0\n",
    "import numpy as np\n",
    "Y = np.arange(minLat,maxLat, latIncrease)\n",
    "X = np.arange(minLon+0.04, maxLon+0.04, lonIncrease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Calculating the knn for Driver Inattention/Distraction, Failure to Yield Right-of-Way,Other Vehicular, Fatigued/Drowsy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### needed to calculate KNN later, took from the book\n",
    "\n",
    "from __future__ import division\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def vector_subtract(v, w):\n",
    "    \"\"\"subtracts two vectors componentwise\"\"\"\n",
    "    return [v_i - w_i for v_i, w_i in zip(v,w)]\n",
    "\n",
    "def dot(v, w):\n",
    "    \"\"\"v_1 * w_1 + ... + v_n * w_n\"\"\"\n",
    "    return sum(v_i * w_i for v_i, w_i in zip(v, w))\n",
    "\n",
    "def sum_of_squares(v):\n",
    "    \"\"\"v_1 * v_1 + ... + v_n * v_n\"\"\"\n",
    "    return dot(v, v)\n",
    "\n",
    "def magnitude(v):\n",
    "    return math.sqrt(sum_of_squares(v))\n",
    "\n",
    "def squared_distance(v, w):\n",
    "    return sum_of_squares(vector_subtract(v, w))\n",
    "\n",
    "def distance(v, w):\n",
    "   return math.sqrt(squared_distance(v, w))\n",
    "\n",
    "def majority_vote(labels):\n",
    "    \"\"\"assumes that labels are ordered from nearest to farthest\"\"\"\n",
    "    vote_counts = Counter(labels)\n",
    "    winner, winner_count = vote_counts.most_common(1)[0]\n",
    "    num_winners = len([count \n",
    "                       for count in vote_counts.values()\n",
    "                       if count == winner_count])\n",
    "\n",
    "    if num_winners == 1:\n",
    "        return winner                     # unique winner, so return it\n",
    "    else:\n",
    "        return majority_vote(labels[:-1]) # try again without the farthest\n",
    "\n",
    "\n",
    "def knn_classify(k, labeled_points, new_point):\n",
    "    \"\"\"each labeled point should be a pair (point, label)\"\"\"\n",
    "    \n",
    "    # order the labeled points from nearest to farthest\n",
    "    by_distance = sorted(labeled_points,\n",
    "                         key=lambda (point, _): distance(point, new_point))\n",
    "\n",
    "    # find the labels for the k closest\n",
    "    k_nearest_labels = [label for _, label in by_distance[:k]]\n",
    "\n",
    "    # and let them vote\n",
    "    return majority_vote(k_nearest_labels)\n",
    "allCrimes = []\n",
    "for index,row in inattention25k.iterrows():\n",
    "    allCrimes.append(([row['LATITUDE'], row['LONGITUDE']],'inattention'))\n",
    "for index,row in fatigued25k.iterrows():\n",
    "    allCrimes.append(([row['LATITUDE'], row['LONGITUDE']],'fatigued'))\n",
    "for index,row in failure25k.iterrows():\n",
    "    allCrimes.append(([row['LATITUDE'], row['LONGITUDE']],'failure'))\n",
    "for index,row in otherVehicle25k.iterrows():\n",
    "    allCrimes.append(([row['LATITUDE'], row['LONGITUDE']],'otherVehicle'))\n",
    "#creating the csv for knn=5\n",
    "inattention5 = open(\"inattention5.csv\",'w')\n",
    "inattention5.write(\"name,lat,lon\\n\")\n",
    "fatigued5 = open(\"fatigued5.csv\",'w')\n",
    "fatigued5.write(\"fatigued5,lat,lon\\n\")\n",
    "otherVehicle5 = open(\"otherVehicle5.csv\",'w')\n",
    "otherVehicle5.write(\"name,lat,lon\\n\")\n",
    "failure5 = open(\"failure5.csv\",'w')\n",
    "failure5.write(\"name,lat,lon\\n\")\n",
    "\n",
    "\n",
    "\n",
    "for y in Y:\n",
    "    for x in X: \n",
    "        c = knn_classify(5, allCrimes, [y,x])\n",
    "        if c=='inattention':\n",
    "            inattention5.write('inattention, %f, %f \\n' %( y, x))\n",
    "        if c=='fatigued':\n",
    "            fatigued5.write('fatigued5, %f, %f \\n' %( y, x))\n",
    "        if c=='otherVehicle':\n",
    "            otherVehicle5.write('otherVehicle, %f, %f \\n' %( y, x))\n",
    "        if c=='failure':\n",
    "            failure5.write('failure, %f, %f \\n' %( y, x))\n",
    "            \n",
    "        \n",
    "inattention5.close()\n",
    "fatigued5.close()\n",
    "otherVehicle5.close()\n",
    "failure5.close()\n",
    "#creating the csv for knn=10\n",
    "\n",
    "inattention10 = open(\"inattention10.csv\",'w')\n",
    "inattention10.write(\"name,lat,lon\\n\")\n",
    "fatigued10 = open(\"fatigued10.csv\",'w')\n",
    "fatigued10.write(\"fatigued10,lat,lon\\n\")\n",
    "otherVehicle10 = open(\"otherVehicle10.csv\",'w')\n",
    "otherVehicle10.write(\"name,lat,lon\\n\")\n",
    "failure10 = open(\"failure10.csv\",'w')\n",
    "failure10.write(\"name,lat,lon\\n\")\n",
    "\n",
    "for y in Y:\n",
    "    for x in X: \n",
    "        c = knn_classify(10, allCrimes, [y,x])\n",
    "        if c=='inattention':\n",
    "            inattention10.write('inattention, %f, %f \\n' %( y, x))\n",
    "        if c=='fatigued':\n",
    "            fatigued10.write('fatigued10, %f, %f \\n' %( y, x))\n",
    "        if c=='otherVehicle':\n",
    "            otherVehicle10.write('otherVehicle, %f, %f \\n' %( y, x))\n",
    "        if c=='failure':\n",
    "            failure10.write('failure, %f, %f \\n' %( y, x))\n",
    "            \n",
    "        \n",
    "inattention10.close()\n",
    "fatigued10.close()\n",
    "otherVehicle10.close()\n",
    "failure10.close()\n",
    "\n",
    "#creating the csv for knn=30\n",
    "inattention30 = open(\"inattention30.csv\",'w')\n",
    "inattention30.write(\"name,lat,lon\\n\")\n",
    "fatigued30 = open(\"fatigued30.csv\",'w')\n",
    "fatigued30.write(\"fatigued30,lat,lon\\n\")\n",
    "otherVehicle30 = open(\"otherVehicle30.csv\",'w')\n",
    "otherVehicle30.write(\"name,lat,lon\\n\")\n",
    "failure30 = open(\"failure30.csv\",'w')\n",
    "failure30.write(\"name,lat,lon\\n\")\n",
    "\n",
    "for y in Y:\n",
    "    for x in X: \n",
    "        c = knn_classify(30, allCrimes, [y,x])\n",
    "        if c=='inattention':\n",
    "            inattention30.write('inattention, %f, %f \\n' %( y, x))\n",
    "        if c=='fatigued':\n",
    "            fatigued30.write('fatigued30, %f, %f \\n' %( y, x))\n",
    "        if c=='otherVehicle':\n",
    "            otherVehicle30.write('otherVehicle, %f, %f \\n' %( y, x))\n",
    "        if c=='failure':\n",
    "            failure30.write('failure, %f, %f \\n' %( y, x))\n",
    "            \n",
    "        \n",
    "inattention30.close()\n",
    "fatigued30.close()\n",
    "otherVehicle30.close()\n",
    "failure30.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the intersections where there were the most crashes by years: 2012,2013,2014,2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfCount = df.groupby(['ON STREET NAME','CROSS STREET NAME']).size().reset_index().rename(columns={0:'count'})\n",
    "failureCount = failure.groupby(['ON STREET NAME','CROSS STREET NAME']).size().reset_index().rename(columns={0:'count'})\n",
    "fatiguedCount = fatigued.groupby(['ON STREET NAME','CROSS STREET NAME']).size().reset_index().rename(columns={0:'count'})\n",
    "inattetionCount = inattetion.groupby(['ON STREET NAME','CROSS STREET NAME']).size().reset_index().rename(columns={0:'count'})\n",
    "otherVehicleCount = otherVehicle.groupby(['ON STREET NAME','CROSS STREET NAME']).size().reset_index().rename(columns={0:'count'})\n",
    "dfCount = dfCount.sort_values('count', ascending=False)\n",
    "inattetionCount =  inattetionCount.sort_values('count', ascending=False)\n",
    "failureCount = failureCount.sort_values('count', ascending=False)\n",
    "fatiguedCount = fatiguedCount.sort_values('count', ascending=False)\n",
    "otherVehicleCount = otherVehicleCount.sort_values('count', ascending=False)\n",
    "#creating masks for each year\n",
    "mask2012 = ( pd.to_datetime(df['DATE'])  >= '2012-1-1') & ( pd.to_datetime(df['DATE'])  < '2013-1-1')\n",
    "mask2013 = ( pd.to_datetime(df['DATE'])  >= '2013-1-1') & ( pd.to_datetime(df['DATE'])  < '2014-1-1')\n",
    "mask2014 = ( pd.to_datetime(df['DATE'])  >= '2014-1-1') & ( pd.to_datetime(df['DATE'])  < '2015-1-1')\n",
    "mask2015 = ( pd.to_datetime(df['DATE'])  >= '2015-1-1') & ( pd.to_datetime(df['DATE'])  < '2016-1-1')\n",
    "mask2016 = ( pd.to_datetime(df['DATE'])  >= '2016-1-1') & ( pd.to_datetime(df['DATE'])  < '2017-1-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating small pandas for each year\n",
    "df2012 = df.loc[mask2012]\n",
    "df2013 = df.loc[mask2013]\n",
    "df2014 = df.loc[mask2014]\n",
    "df2015 = df.loc[mask2015]\n",
    "df2016 = df.loc[mask2016]\n",
    "#getting the intersections for each year and sort them descending \n",
    "dfCount2012 = df2012.groupby(['ON STREET NAME','CROSS STREET NAME']).size().reset_index().rename(columns={0:'count'})\n",
    "dfCount2012 = dfCount2012.sort_values('count', ascending=False)\n",
    "dfCount2013 = df2013.groupby(['ON STREET NAME','CROSS STREET NAME']).size().reset_index().rename(columns={0:'count'})\n",
    "dfCount2013 = dfCount2013.sort_values('count', ascending=False)\n",
    "dfCount2014 = df2014.groupby(['ON STREET NAME','CROSS STREET NAME']).size().reset_index().rename(columns={0:'count'})\n",
    "dfCount2014 = dfCount2014.sort_values('count', ascending=False)\n",
    "dfCount2015 = df2015.groupby(['ON STREET NAME','CROSS STREET NAME']).size().reset_index().rename(columns={0:'count'})\n",
    "dfCount2015 = dfCount2015.sort_values('count', ascending=False)\n",
    "dfCount2016 = df2016.groupby(['ON STREET NAME','CROSS STREET NAME']).size().reset_index().rename(columns={0:'count'})\n",
    "dfCount2016 = dfCount2016.sort_values('count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#creating the csv files with the intersection data\n",
    "streetNames2012 = []\n",
    "crossStreetNames2012 = []\n",
    "count2012 = []\n",
    "counter =0 \n",
    "for i in  dfCount2012['ON STREET NAME']:\n",
    "    streetNames2012.append(i)\n",
    "    counter = counter +1 \n",
    "    if counter==10:\n",
    "        break\n",
    "counter =0 \n",
    "for i in  dfCount2012['CROSS STREET NAME']:\n",
    "    crossStreetNames2012.append(i)\n",
    "    counter = counter +1 \n",
    "    if counter==10:\n",
    "        break      \n",
    "counter =0 \n",
    "for i in  dfCount2012['count']:\n",
    "    count2012.append(i)\n",
    "    counter = counter +1 \n",
    "    if counter==10:\n",
    "        break      \n",
    "dfs = [df2013,df2014,df2015,df2016]\n",
    "count2013= []\n",
    "count2014= []\n",
    "count2015= []\n",
    "count2016= []\n",
    "countAll = [count2013,count2014,count2015,count2016]\n",
    "\n",
    "x =0 \n",
    "for dfX in dfs:\n",
    "    for i in range(0,10):\n",
    "        aMask = ( dfX['ON STREET NAME']  == streetNames2012[i]) & ( dfX['CROSS STREET NAME']  == crossStreetNames2012[i])\n",
    "        countAll[x].append( len(dfX.loc[aMask]))\n",
    "    x = x+1\n",
    "\n",
    "    \n",
    "f = open('intersections.csv', 'w')\n",
    "for i in range(0,10):\n",
    "    f.write('date,%s With %s,'%(streetNames2012[i],crossStreetNames2012[i]))\n",
    "f.write('\\n')\n",
    "years =['1-Jan-2013','1-Jan-2014','1-Jan-2015','1-Jan-2016']\n",
    "year= 0\n",
    "for i in countAll:\n",
    "    f.write('%s,'%years[year])\n",
    "    for j in range(0,10):\n",
    "        f.write('%i,'%countAll[year][j])\n",
    "    year = year + 1\n",
    "    f.write('\\n')\n",
    "f.write('1-Jan-2012,')\n",
    "for i in count2012: \n",
    "     f.write('%i,'%i)\n",
    "f.write(\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Getting the data necessary for day hour heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alltheyears = pd.date_range(start=pd.datetime(2012, 1, 1), periods=365*5, freq='D')\n",
    "w, h = 7, 24;\n",
    "Matrix = [[0 for x in range(h)] for y in range(w)] \n",
    "weekA_actualResults = []\n",
    "for i in range(0,365*5):\n",
    "    k = '{:%m/%d/%Y}'.format(alltheyears[i])\n",
    "    weekday = alltheyears[i].weekday()\n",
    "    dfPerDay  = df.loc[df['DATE']==k]\n",
    "    for j in range(0,24):\n",
    "        \n",
    "        if j<9:\n",
    "            maskH  = (dfPerDay['TIME']>= '%i:00'%j) & (dfPerDay['TIME']<='%i:00'%(j+1))\n",
    "        else:\n",
    "            if j==9:\n",
    "                maskH  = (dfPerDay['TIME']>= '%i:00'%j) & (dfPerDay['TIME']<='%i:00'%(j+1))\n",
    "            else:\n",
    "                maskH  = (dfPerDay['TIME']>= '%i:00'%j) & (dfPerDay['TIME']<='%i:00'%(j+1))\n",
    "        dfPerHour = dfPerDay.loc[maskH]\n",
    "        Matrix[weekday][j] =  Matrix[weekday][j] + len(dfPerHour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('data1.tsv', 'w')\n",
    "f.write(\"day hour value\\n\")\n",
    "for i in range(0,7):\n",
    "    for j in range(0,24):\n",
    "            s = '%i %i %i\\n'%(i,j, Matrix[i][j])\n",
    "            f.write(s)\n",
    "f.close()\n",
    "MatrixFatigued = [[0 for x in range(h)] for y in range(w)] \n",
    "for i in range(0,365*5):\n",
    "    k = '{:%m/%d/%Y}'.format(alltheyears[i])\n",
    "    weekday = alltheyears[i].weekday()\n",
    "    fatiguedPerDay  = fatigued.loc[fatigued['DATE']==k]\n",
    "    for j in range(0,24):\n",
    "        if j+1!=24:\n",
    "            fatiguedPerHour = fatiguedPerDay.between_time( '%i:00:00'%j, '%i:00:00'%((j+1)) )\n",
    "        else:\n",
    "            fatiguedPerHour = fatiguedPerDay.between_time( '%i:00:00'%j, '%i:00:00'%(0 ))\n",
    "        MatrixFatigued[weekday][j] =  MatrixFatigued[weekday][j] + len(fatiguedPerHour)\n",
    "        \n",
    "f = open('dataFatigued.tsv', 'w')\n",
    "f.write(\"day hour value\\n\")\n",
    "for i in range(0,7):\n",
    "    for j in range(0,24):\n",
    "        if(j>=2):\n",
    "            s = '%i %i %i\\n'%(i,j, MatrixFatigued[i][j])\n",
    "            f.write(s)\n",
    "f.close()\n",
    "MatrixFailure = [[0 for x in range(h)] for y in range(w)] \n",
    "for i in range(0,365*5):\n",
    "    k = '{:%m/%d/%Y}'.format(alltheyears[i])\n",
    "    weekday = alltheyears[i].weekday()\n",
    "    failurePerDay  = failure.loc[failure['DATE']==k]\n",
    "    for j in range(0,24):\n",
    "        if j+1!=24:\n",
    "            failurePerHour = failurePerDay.between_time( '%i:00:00'%j, '%i:00:00'%((j+1)) )\n",
    "        else:\n",
    "            failurePerHour = failurePerDay.between_time( '%i:00:00'%j, '%i:00:00'%((0) ))\n",
    "        MatrixFailure[weekday][j] =  MatrixFailure[weekday][j] + len(failurePerHour)\n",
    "f = open('dataFailure.tsv', 'w')\n",
    "f.write(\"day hour value\\n\")\n",
    "for i in range(0,7):\n",
    "    for j in range(0,24):\n",
    "        if(j>=2):\n",
    "            s = '%i %i %i\\n'%(i,j, MatrixFailure[i][j])\n",
    "            f.write(s)\n",
    "f.close()\n",
    "MatrixotherVehicle = [[0 for x in range(h)] for y in range(w)] \n",
    "for i in range(0,365*5):\n",
    "    k = '{:%m/%d/%Y}'.format(alltheyears[i])\n",
    "    weekday = alltheyears[i].weekday()\n",
    "    otherVehiclePerDay  = otherVehicle.loc[otherVehicle['DATE']==k]\n",
    "    for j in range(0,24):\n",
    "        if j+1!=24:\n",
    "            otherVehiclePerHour = otherVehiclePerDay.between_time( '%i:00:00'%j, '%i:00:00'%((j+1)) )\n",
    "        else: \n",
    "            otherVehiclePerHour = otherVehiclePerDay.between_time( '%i:00:00'%j, '%i:00:00'%((0)) )\n",
    "        MatrixotherVehicle[weekday][j] =  MatrixotherVehicle[weekday][j] + len(otherVehiclePerHour)\n",
    "f = open('dataotherVehicle.tsv', 'w')\n",
    "f.write(\"day hour value\\n\")\n",
    "for i in range(0,7):\n",
    "    for j in range(0,24):\n",
    "        if(j>=2):\n",
    "            s = '%i %i %i\\n'%(i,j, MatrixotherVehicle[i][j])\n",
    "            f.write(s)\n",
    "f.close()\n",
    "Matrixinattetion = [[0 for x in range(h)] for y in range(w)] \n",
    "for i in range(0,365*5):\n",
    "    k = '{:%m/%d/%Y}'.format(alltheyears[i])\n",
    "    weekday = alltheyears[i].weekday()\n",
    "    inattetionPerDay  = inattetion.loc[inattetion['DATE']==k]\n",
    "    for j in range(0,24):\n",
    "        \n",
    "        if j+1!=24:\n",
    "            inattetionPerHour = inattetionPerDay.between_time( '%i:00:00'%j, '%i:00:00'%((j+1)) )\n",
    "        else: \n",
    "            inattetionPerHour = inattetionPerDay.between_time( '%i:00:00'%j, '%i:00:00'%((0)) )\n",
    "        Matrixinattetion[weekday][j] =  Matrixinattetion[weekday][j] + len(inattetionPerHour)\n",
    "f = open('datainattetion.tsv', 'w')\n",
    "f.write(\"day hour value\\n\")\n",
    "for i in range(0,7):\n",
    "    for j in range(0,24):\n",
    "        if(j>=2):\n",
    "            s = '%i %i %i\\n'%(i,j, Matrixinattetion[i][j])\n",
    "            f.write(s)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data into boroughs and calculating the percentage of the most contributing factors for each borrow, as well the street with the most crashes for each borough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#getting the boroughs\n",
    "staten = df.loc[df['BOROUGH'] == \"STATEN ISLAND\"]\n",
    "bronx = df.loc[df['BOROUGH'] == \"BRONX\"]\n",
    "manhattan  =  df.loc[df['BOROUGH'] == \"MANHATTAN\"]\n",
    "queens =   df.loc[df['BOROUGH'] == \"QUEENS\"]\n",
    "brooklyn = df.loc[df['BOROUGH'] == \"BROOKLYN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#getting contributings factors for each borrow\n",
    "statenContributing = pd.value_counts(staten['CONTRIBUTING FACTOR VEHICLE 1'].values, sort=True)\n",
    "statenContributing = statenContributing[1:8]\n",
    "bronxContributing = pd.value_counts(bronx['CONTRIBUTING FACTOR VEHICLE 1'].values, sort=True)\n",
    "bronxContributing = bronxContributing[1:8]\n",
    "manhattanContributing = pd.value_counts(manhattan['CONTRIBUTING FACTOR VEHICLE 1'].values, sort=True)\n",
    "manhattanContributing = manhattanContributing[1:8]\n",
    "queensContributing = pd.value_counts(queens['CONTRIBUTING FACTOR VEHICLE 1'].values, sort=True)\n",
    "queensContributing = queensContributing[1:8]\n",
    "brooklynContributing = pd.value_counts(brooklyn['CONTRIBUTING FACTOR VEHICLE 1'].values, sort=True)\n",
    "brooklynContributing = brooklynContributing[1:8]\n",
    "#getting the streets for each borough\n",
    "statenStreets = pd.value_counts(staten['ON STREET NAME'].values, sort=True)\n",
    "statenStreets = statenStreets[0:8]\n",
    "bronxStreets = pd.value_counts(bronx['ON STREET NAME'].values, sort=True)\n",
    "bronxStreets = bronxStreets[1:9]\n",
    "manhattanStreets = pd.value_counts(manhattan['ON STREET NAME'].values, sort=True)\n",
    "manhattanStreets = manhattanStreets[0:9]\n",
    "queensStreets = pd.value_counts(queens['ON STREET NAME'].values, sort=True)\n",
    "queensStreets = queensStreets[0:9]\n",
    "brooklynStreets = pd.value_counts(brooklyn['ON STREET NAME'].values, sort=True)\n",
    "brooklynStreets = brooklynStreets[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#writting the contributing factors to the csv\n",
    "from random import randint\n",
    "f = open(\"contributing.csv\", \"w\")\n",
    "f.write(\"id,value,color\\n\")\n",
    "f.write(\"NewYork,\\n\")\n",
    "s= \"NewYork.Staten Island\"\n",
    "f.write(s)\n",
    "f.write(\",\\n\")\n",
    "for row in statenContributing.iteritems():\n",
    "    if row[0]!=\"\":\n",
    "        f.write('%s.%s,%f,%s\\n'%(s,row[0],row[1]*100.0/len(staten),'#%06X' % randint(0, 0xFFFFFF)))\n",
    "        \n",
    "s= \"NewYork.Bronx\"\n",
    "f.write(s)\n",
    "f.write(\",\\n\")\n",
    "for row in bronxContributing.iteritems():\n",
    "    if row[0]!=\"\":\n",
    "        f.write('%s.%s,%f,%s\\n'%(s,row[0],row[1]*100.0/len(bronx),'#%06X' % randint(0, 0xFFFFFF)))\n",
    "\n",
    "s= \"NewYork.Manhattan\"\n",
    "f.write(s)\n",
    "f.write(\",\\n\")\n",
    "for row in manhattanContributing.iteritems():\n",
    "    if row[0]!=\"\":\n",
    "        f.write('%s.%s,%f,%s\\n'%(s,row[0],row[1]*100.0/len(manhattan),'#%06X' % randint(0, 0xFFFFFF)))\n",
    "\n",
    "s= \"NewYork.Queens\"\n",
    "f.write(s)\n",
    "f.write(\",\\n\")\n",
    "for row in queensContributing.iteritems():\n",
    "    if row[0]!=\"\":\n",
    "        f.write('%s.%s,%f,%s\\n'%(s,row[0],row[1]*100.0/len(queens),'#%06X' % randint(0, 0xFFFFFF)))\n",
    "\n",
    "s= \"NewYork.Brooklyn\"\n",
    "f.write(s)\n",
    "f.write(\",\\n\")\n",
    "for row in brooklynContributing.iteritems():\n",
    "    if row[0]!=\"\":\n",
    "        f.write('%s.%s,%f,%s\\n'%(s,row[0],row[1]*100.0/len(brooklyn),'#%06X' % randint(0, 0xFFFFFF)))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#writting the street names for each borough on csv\n",
    "from random import randint\n",
    "f = open(\"streets.csv\", \"w\")\n",
    "f.write(\"id,value,color\\n\")\n",
    "f.write(\"NewYork,\\n\")\n",
    "s= \"NewYork.Staten Island\"\n",
    "f.write(s)\n",
    "f.write(\",\\n\")\n",
    "for row in statenStreets.iteritems():\n",
    "    if row[0]!=\"\":\n",
    "        f.write('%s.%s,%f,%s\\n'%(s,row[0],row[1]*100.0/len(staten),'#%06X' % randint(0, 0xFFFFFF)))\n",
    "        \n",
    "s= \"NewYork.Bronx\"\n",
    "f.write(s)\n",
    "f.write(\",\\n\")\n",
    "for row in bronxStreets.iteritems():\n",
    "    if row[0]!=\"\":\n",
    "        f.write('%s.%s,%f,%s\\n'%(s,row[0],row[1]*100.0/len(bronx),'#%06X' % randint(0, 0xFFFFFF)))\n",
    "\n",
    "s= \"NewYork.Manhattan\"\n",
    "f.write(s)\n",
    "f.write(\",\\n\")\n",
    "for row in manhattanStreets.iteritems():\n",
    "    if row[0]!=\"\":\n",
    "        f.write('%s.%s,%f,%s\\n'%(s,row[0],row[1]*100.0/len(manhattan),'#%06X' % randint(0, 0xFFFFFF)))\n",
    "\n",
    "s= \"NewYork.Queens\"\n",
    "f.write(s)\n",
    "f.write(\",\\n\")\n",
    "for row in queensStreets.iteritems():\n",
    "    if row[0]!=\"\":\n",
    "        f.write('%s.%s,%f,%s\\n'%(s,row[0],row[1]*100.0/len(queens),'#%06X' % randint(0, 0xFFFFFF)))\n",
    "\n",
    "s= \"NewYork.Brooklyn\"\n",
    "f.write(s)\n",
    "f.write(\",\\n\")\n",
    "for row in brooklynStreets.iteritems():\n",
    "    if row[0]!=\"\":\n",
    "        f.write('%s.%s,%f,%s\\n'%(s,row[0],row[1]*100.0/len(brooklyn),'#%06X' % randint(0, 0xFFFFFF)))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
